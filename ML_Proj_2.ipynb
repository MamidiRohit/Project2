{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import log\n",
    "\n",
    "# Load dataset\n",
    "wine_data = pd.read_csv('winedata.csv', delimiter=';')\n",
    "X = wine_data.drop(columns='quality').values\n",
    "y = wine_data['quality'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Linear Regression model\n",
    "class CustomLinearRegression:\n",
    "    def __init__(self):\n",
    "        self.coef_ = None\n",
    "        self.intercept_ = 0\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Adding bias term for intercept\n",
    "        X_bias = np.c_[np.ones(X.shape[0]), X]\n",
    "        # Normal equation: (X.T * X)^(-1) * X.T * y\n",
    "        XtX_inv = np.linalg.inv(X_bias.T.dot(X_bias))\n",
    "        self.coef_ = XtX_inv.dot(X_bias.T).dot(y)\n",
    "        self.intercept_ = self.coef_[0]\n",
    "        self.coef_ = self.coef_[1:]\n",
    "\n",
    "    def predict(self, X):\n",
    "        return X.dot(self.coef_) + self.intercept_\n",
    "\n",
    "# Define k-Fold Cross-Validation function\n",
    "def custom_k_fold_cross_validation(X, y, model, k=5):\n",
    "    np.random.seed(42)\n",
    "    indices = np.random.permutation(len(X))\n",
    "    fold_size = len(X) // k\n",
    "    mse_scores = []\n",
    "\n",
    "    for i in range(k):\n",
    "        val_indices = indices[i * fold_size : (i + 1) * fold_size]\n",
    "        train_indices = np.setdiff1d(indices, val_indices)\n",
    "\n",
    "        X_train, X_val = X[train_indices], X[val_indices]\n",
    "        y_train, y_val = y[train_indices], y[val_indices]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_val)\n",
    "        mse_scores.append(np.mean((y_val - y_pred) ** 2))\n",
    "\n",
    "    return np.mean(mse_scores), np.std(mse_scores)\n",
    "\n",
    "# Define Bootstrapping function\n",
    "def custom_bootstrap_model_selection(X, y, model, n_iterations=100):\n",
    "    mse_scores = []\n",
    "    np.random.seed(42)\n",
    "\n",
    "    for _ in range(n_iterations):\n",
    "        # Bootstrap resample\n",
    "        resample_indices = np.random.choice(range(len(X)), size=len(X), replace=True)\n",
    "        X_resample, y_resample = X[resample_indices], y[resample_indices]\n",
    "\n",
    "        model.fit(X_resample, y_resample)\n",
    "        y_pred = model.predict(X)\n",
    "        mse_scores.append(np.mean((y - y_pred) ** 2))\n",
    "\n",
    "    return np.mean(mse_scores), np.std(mse_scores)\n",
    "\n",
    "# Define AIC calculation function\n",
    "def calculate_aic(X, y, model):\n",
    "    model.fit(X, y)\n",
    "    y_pred = model.predict(X)\n",
    "    mse = np.mean((y - y_pred) ** 2)\n",
    "    n = len(y)\n",
    "    k = X.shape[1]\n",
    "    aic = n * log(mse) + 2 * k\n",
    "    return aic\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Custom Evaluation metrics for classification\n",
    "def calculate_accuracy(y_true, y_pred):\n",
    "    correct = np.sum(y_true == y_pred)\n",
    "    return correct / len(y_true)\n",
    "\n",
    "def calculate_precision(y_true, y_pred):\n",
    "    true_positive = np.sum((y_pred == 1) & (y_true == 1))\n",
    "    predicted_positive = np.sum(y_pred == 1)\n",
    "    return true_positive / predicted_positive if predicted_positive != 0 else 0\n",
    "\n",
    "def calculate_recall(y_true, y_pred):\n",
    "    true_positive = np.sum((y_pred == 1) & (y_true == 1))\n",
    "    actual_positive = np.sum(y_true == 1)\n",
    "    return true_positive / actual_positive if actual_positive != 0 else 0\n",
    "\n",
    "def calculate_f1_score(precision, recall):\n",
    "    return 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation metrics for regression\n",
    "def evaluate_metrics(y_true, y_pred, task_type='regression'):\n",
    "    if task_type == 'regression':\n",
    "        # Regression metrics\n",
    "        mse = np.mean((y_true - y_pred) ** 2)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = np.mean(np.abs(y_true - y_pred))\n",
    "        r2 = 1 - (np.sum((y_true - y_pred) ** 2) / np.sum((y_true - np.mean(y_true)) ** 2))\n",
    "        \n",
    "        print(\"Regression Metrics:\")\n",
    "        print(\"Mean Squared Error (MSE):\", mse)\n",
    "        print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "        print(\"Mean Absolute Error (MAE):\", mae)\n",
    "        print(\"R^2 Score:\", r2)\n",
    "        return {'MSE': mse, 'RMSE': rmse, 'MAE': mae, 'R2': r2}\n",
    "    \n",
    "\n",
    "    elif task_type == 'classification':\n",
    "        # Classification metrics\n",
    "        accuracy = calculate_accuracy(y_true, y_pred)\n",
    "        precision = calculate_precision(y_true, y_pred)\n",
    "        recall = calculate_recall(y_true, y_pred)\n",
    "        f1 = calculate_f1_score(precision, recall)\n",
    "\n",
    "        print(\"\\nClassification Metrics:\")\n",
    "        print(\"Accuracy:\", accuracy)\n",
    "        print(\"Precision (Weighted):\", precision)\n",
    "        print(\"Recall (Weighted):\", recall)\n",
    "        print(\"F1 Score (Weighted):\", f1)\n",
    "        \n",
    "        metrics = {'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1 Score': f1}\n",
    "        \n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-Fold Cross-Validation Mean MSE: 0.5675070238740973\n",
      "k-Fold Cross-Validation Std MSE: 0.024211861662026154\n",
      "Bootstrapping Mean MSE: 0.5652007623900872\n",
      "Bootstrapping Std MSE: 0.0009890211204771238\n",
      "Regression Metrics:\n",
      "Mean Squared Error (MSE): 0.5631540629886554\n",
      "Root Mean Squared Error (RMSE): 0.7504359153109981\n",
      "Mean Absolute Error (MAE): 0.5836349500197301\n",
      "R^2 Score: 0.28187036413328725\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.5631540629886554,\n",
       " 'RMSE': 0.7504359153109981,\n",
       " 'MAE': 0.5836349500197301,\n",
       " 'R2': 0.28187036413328725}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and evaluate a regression model\n",
    "linear_model = CustomLinearRegression()\n",
    "\n",
    "# k-Fold Cross-Validation for Regression\n",
    "k_fold_mean_mse, k_fold_std_mse = custom_k_fold_cross_validation(X, y, linear_model, k=5)\n",
    "print(\"k-Fold Cross-Validation Mean MSE:\", k_fold_mean_mse)\n",
    "print(\"k-Fold Cross-Validation Std MSE:\", k_fold_std_mse)\n",
    "\n",
    "# Bootstrapping for Regression\n",
    "bootstrap_mean_mse, bootstrap_std_mse = custom_bootstrap_model_selection(X, y, linear_model, n_iterations=100)\n",
    "print(\"Bootstrapping Mean MSE:\", bootstrap_mean_mse)\n",
    "print(\"Bootstrapping Std MSE:\", bootstrap_std_mse)\n",
    "\n",
    "# Regression metrics on entire dataset\n",
    "linear_model.fit(X, y)\n",
    "y_pred = linear_model.predict(X)\n",
    "evaluate_metrics(y, y_pred, task_type='regression')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "863978f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# Custom K-Fold Cross-Validation Implementation\n",
    "def custom_k_fold_split(X, y, k=5, random_state=42):\n",
    "    np.random.seed(random_state)\n",
    "    indices = np.random.permutation(len(X))\n",
    "    fold_size = len(X) // k\n",
    "    folds = []\n",
    "\n",
    "    for i in range(k):\n",
    "        val_indices = indices[i * fold_size: (i + 1) * fold_size]\n",
    "        train_indices = np.setdiff1d(indices, val_indices)\n",
    "        folds.append((train_indices, val_indices))\n",
    "    \n",
    "    return folds\n",
    "\n",
    "# Custom Decision Tree (simple version, as Random Forests require a set of trees)\n",
    "class CustomDecisionTree:\n",
    "    def __init__(self, max_depth=None):\n",
    "        self.max_depth = max_depth\n",
    "        self.tree = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.tree = self._build_tree(X, y, depth=0)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._predict_row(row, self.tree) for row in X])\n",
    "\n",
    "    def _build_tree(self, X, y, depth):\n",
    "        # Base cases for stopping\n",
    "        if len(set(y)) == 1 or (self.max_depth is not None and depth >= self.max_depth):\n",
    "            return Counter(y).most_common(1)[0][0]\n",
    "\n",
    "        # Random feature selection for split (simplified for demonstration)\n",
    "        feature_idx = np.random.choice(X.shape[1])\n",
    "        median = np.median(X[:, feature_idx])\n",
    "\n",
    "        left_idx = X[:, feature_idx] <= median\n",
    "        right_idx = X[:, feature_idx] > median\n",
    "\n",
    "        if sum(left_idx) == 0 or sum(right_idx) == 0:  # Prevent split if one side is empty\n",
    "            return Counter(y).most_common(1)[0][0]\n",
    "\n",
    "        return {\n",
    "            \"feature\": feature_idx,\n",
    "            \"threshold\": median,\n",
    "            \"left\": self._build_tree(X[left_idx], y[left_idx], depth + 1),\n",
    "            \"right\": self._build_tree(X[right_idx], y[right_idx], depth + 1)\n",
    "        }\n",
    "\n",
    "    def _predict_row(self, row, tree):\n",
    "        if not isinstance(tree, dict):  # If the tree is a leaf node\n",
    "            return tree\n",
    "        feature, threshold = tree[\"feature\"], tree[\"threshold\"]\n",
    "        if row[feature] <= threshold:\n",
    "            return self._predict_row(row, tree[\"left\"])\n",
    "        else:\n",
    "            return self._predict_row(row, tree[\"right\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07d0f27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Random Forest Classifier\n",
    "class CustomRandomForest:\n",
    "    def __init__(self, n_estimators=10, max_depth=None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.trees = []\n",
    "        for _ in range(self.n_estimators):\n",
    "            # Bootstrap sampling\n",
    "            indices = np.random.choice(range(len(X)), size=len(X), replace=True)\n",
    "            X_sample, y_sample = X[indices], y[indices]\n",
    "            tree = CustomDecisionTree(max_depth=self.max_depth)\n",
    "            tree.fit(X_sample, y_sample)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Collect predictions from each tree\n",
    "        tree_preds = np.array([tree.predict(X) for tree in self.trees])\n",
    "        # Majority voting\n",
    "        majority_votes = [Counter(tree_preds[:, i]).most_common(1)[0][0] for i in range(X.shape[0])]\n",
    "        return np.array(majority_votes)\n",
    "\n",
    "# Testing with custom K-Fold and Random Forest on provided data\n",
    "def custom_random_forest_k_fold(X, y, n_splits=5, n_estimators=10, max_depth=None):\n",
    "    folds = custom_k_fold_split(X, y, k=n_splits)\n",
    "    y_true_all, y_pred_all = [], []\n",
    "\n",
    "    for train_idx, val_idx in folds:\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "        \n",
    "        # Initialize and train Custom Random Forest\n",
    "        clf = CustomRandomForest(n_estimators=n_estimators, max_depth=max_depth)\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions and accumulate results\n",
    "        y_pred = clf.predict(X_val)\n",
    "        y_true_all.extend(y_val)\n",
    "        y_pred_all.extend(y_pred)\n",
    "\n",
    "    return np.array(y_true_all), np.array(y_pred_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36c1979a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Metrics:\n",
      "Accuracy: 0.7120654396728017\n",
      "Precision (Weighted): 0.715219421101774\n",
      "Recall (Weighted): 0.942189421894219\n",
      "F1 Score (Weighted): 0.8131634819532909\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.7120654396728017,\n",
       " 'Precision': 0.715219421101774,\n",
       " 'Recall': 0.942189421894219,\n",
       " 'F1 Score': 0.8131634819532909}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_class = (y >= 6).astype(int)\n",
    "# Convert data to numpy arrays if necessary\n",
    "X = np.array(X)\n",
    "y_class = np.array(y_class)\n",
    "\n",
    "# Run custom K-Fold with Custom Random Forest\n",
    "y_true_all, y_pred_all = custom_random_forest_k_fold(X, y_class, n_splits=10, n_estimators=10, max_depth=5)\n",
    "\n",
    "evaluate_metrics(y_true_all, y_pred_all, task_type='classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing our custom random forest k fold with other dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of      sepal_length  sepal_width  petal_length  petal_width    species\n",
       "0             5.1          3.5           1.4          0.2     setosa\n",
       "1             4.9          3.0           1.4          0.2     setosa\n",
       "2             4.7          3.2           1.3          0.2     setosa\n",
       "3             4.6          3.1           1.5          0.2     setosa\n",
       "4             5.0          3.6           1.4          0.2     setosa\n",
       "..            ...          ...           ...          ...        ...\n",
       "145           6.7          3.0           5.2          2.3  virginica\n",
       "146           6.3          2.5           5.0          1.9  virginica\n",
       "147           6.5          3.0           5.2          2.0  virginica\n",
       "148           6.2          3.4           5.4          2.3  virginica\n",
       "149           5.9          3.0           5.1          1.8  virginica\n",
       "\n",
       "[150 rows x 5 columns]>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"iris.csv\"\n",
    "iris_data = pd.read_csv(file_path)\n",
    "\n",
    "iris_data.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of new model using our random forest k fold\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_newdataset = iris_data.drop(columns='species').values\n",
    "y_newdataset = iris_data['species'].values\n",
    "\n",
    "\n",
    "y_true_all, y_pred_all = custom_random_forest_k_fold(X_newdataset, y_newdataset, n_splits=3, n_estimators=10, max_depth=5)\n",
    "\n",
    "print(\"Accuracy of new model using our random forest k fold\\n\")\n",
    "calculate_accuracy(y_true_all, y_pred_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing our custom linear regression k fold with other dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of         RM  LSTAT  PTRATIO      MEDV\n",
       "0    6.575   4.98     15.3  504000.0\n",
       "1    6.421   9.14     17.8  453600.0\n",
       "2    7.185   4.03     17.8  728700.0\n",
       "3    6.998   2.94     18.7  701400.0\n",
       "4    7.147   5.33     18.7  760200.0\n",
       "..     ...    ...      ...       ...\n",
       "484  6.593   9.67     21.0  470400.0\n",
       "485  6.120   9.08     21.0  432600.0\n",
       "486  6.976   5.64     21.0  501900.0\n",
       "487  6.794   6.48     21.0  462000.0\n",
       "488  6.030   7.88     21.0  249900.0\n",
       "\n",
       "[489 rows x 4 columns]>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"housing.csv\"\n",
    "housing_data = pd.read_csv(file_path)\n",
    "\n",
    "housing_data.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression Metrics:\n",
      "Mean Squared Error (MSE): 7703545538.8708105\n",
      "Root Mean Squared Error (RMSE): 87769.84413151712\n",
      "Mean Absolute Error (MAE): 65458.43964023349\n",
      "R^2 Score: 0.7176275212982739\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'MSE': 7703545538.8708105,\n",
       " 'RMSE': 87769.84413151712,\n",
       " 'MAE': 65458.43964023349,\n",
       " 'R2': 0.7176275212982739}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_housing = housing_data.drop(columns='MEDV').values\n",
    "y_housing = housing_data['MEDV'].values\n",
    "\n",
    "linear_model.fit(X_housing, y_housing)\n",
    "y_pred_housing = linear_model.predict(X_housing)\n",
    "evaluate_metrics(y_housing, y_pred_housing, task_type='regression')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
