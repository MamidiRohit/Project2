# -*- coding: utf-8 -*-
"""test.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Fjs2CSZdcCGAWHXx_LI_sN-UXqUhPZFt
"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeRegressor
from sklearn.preprocessing import RobustScaler
from sklearn.metrics import mean_squared_error, r2_score

class GradientBoostingRegressor:
    def __init__(self, n_estimators=100, learning_rate=0.1, max_depth=3, random_state=None):

        self.n_estimators = n_estimators
        self.learning_rate = learning_rate
        self.max_depth = max_depth
        self.random_state = random_state

        # Storage for trees and initial prediction
        self.trees = []
        self.base_prediction = None

    def fit(self, X, y):

        # Set random seed for reproducibility
        np.random.seed(self.random_state)

        # Initial prediction is mean of target values
        self.base_prediction = np.mean(y)

        # Initialize predictions with base prediction
        current_pred = np.full(len(y), self.base_prediction)

        # Iteratively build trees to minimize residuals
        for _ in range(self.n_estimators):
            # Compute negative gradient (residuals)
            residuals = y - current_pred

            # Fit regression tree to residuals
            tree = DecisionTreeRegressor(
                max_depth=self.max_depth,
                random_state=self.random_state
            )
            tree.fit(X, residuals)

            # Update predictions with learning rate scaled tree prediction
            current_pred += self.learning_rate * tree.predict(X)

            # Store the tree
            self.trees.append(tree)

        return self

    def predict(self, X):

        # Start with base prediction
        predictions = np.full(len(X), self.base_prediction)

        # Add learning-rate scaled predictions from each tree
        for tree in self.trees:
            predictions += self.learning_rate * tree.predict(X)

        return predictions

def load_data(filename):
    data = np.loadtxt(filename, delimiter=',', skiprows=1)
    X = data[:, :-1]
    y = data[:, -1]
    return X, y

def evaluate_model(X, y, model):
    """Evaluate model performance"""
    predictions = model.predict(X)
    mse = mean_squared_error(y, predictions)
    r2 = r2_score(y, predictions)

    plt.figure(figsize=(10, 6))
    plt.scatter(y, predictions, alpha=0.5)
    plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--', lw=2)
    plt.title('Actual vs Predicted Values')
    plt.xlabel('Actual Values')
    plt.ylabel('Predicted Values')
    plt.show()

    print(f"Mean Squared Error: {mse}")
    print(f"RÂ² Score: {r2}")

    return predictions

def main():
    # Load and scale data
    X, y = load_data('data.csv')
    scaler = RobustScaler()
    X_scaled = scaler.fit_transform(X)

    # Initialize and fit gradient boosting model
    gb_model = GradientBoostingRegressor(
        n_estimators=100,
        learning_rate=0.1,
        max_depth=3,
        random_state=42
    )
    gb_model.fit(X_scaled, y)

    # Evaluate model
    predictions = evaluate_model(X_scaled, y, gb_model)

if __name__ == "__main__":
    main()